{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60fc339a",
   "metadata": {},
   "source": [
    "# Eye Vessel Segmentation - U-Net Model Training\n",
    "\n",
    "This notebook contains the training pipeline for the U-Net model used in the hackathon solution.\n",
    "\n",
    "## Overview\n",
    "- **Task**: Semantic segmentation of blood vessels in slit-lamp eye images\n",
    "- **Model**: U-Net architecture optimized for medical image segmentation\n",
    "- **Data**: Slit-lamp images with GeoJSON annotations\n",
    "- **Metric**: F1 Score optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97ae54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU Available: {tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3782b5c",
   "metadata": {},
   "source": [
    "## Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78254cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "IMG_SIZE = 512\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 50\n",
    "LEARNING_RATE = 1e-4\n",
    "\n",
    "# Paths\n",
    "TRAIN_DATA_PATH = '../dataset/train_dataset_mc'\n",
    "MODEL_SAVE_PATH = '../backend/models/unet_eye_segmentation.keras'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c040c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_geojson_mask(geojson_path, image_shape):\n",
    "    \"\"\"\n",
    "    Convert GeoJSON annotations to binary mask.\n",
    "    \"\"\"\n",
    "    with open(geojson_path, 'r') as f:\n",
    "        geojson_data = json.load(f)\n",
    "    \n",
    "    mask = np.zeros(image_shape[:2], dtype=np.uint8)\n",
    "    \n",
    "    for feature in geojson_data.get('features', []):\n",
    "        geometry = feature.get('geometry', {})\n",
    "        if geometry.get('type') == 'Polygon':\n",
    "            coordinates = geometry.get('coordinates', [])\n",
    "            for polygon in coordinates:\n",
    "                pts = np.array(polygon, dtype=np.int32)\n",
    "                cv2.fillPoly(mask, [pts], 255)\n",
    "        elif geometry.get('type') == 'MultiPolygon':\n",
    "            coordinates = geometry.get('coordinates', [])\n",
    "            for multi_polygon in coordinates:\n",
    "                for polygon in multi_polygon:\n",
    "                    pts = np.array(polygon, dtype=np.int32)\n",
    "                    cv2.fillPoly(mask, [pts], 255)\n",
    "    \n",
    "    return mask\n",
    "\n",
    "def load_dataset(data_path):\n",
    "    \"\"\"\n",
    "    Load images and corresponding masks from the dataset.\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    masks = []\n",
    "    \n",
    "    # Get all PNG files\n",
    "    image_files = glob.glob(os.path.join(data_path, '*.png'))\n",
    "    \n",
    "    for image_path in tqdm(image_files, desc=\"Loading dataset\"):\n",
    "        # Load image\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            continue\n",
    "        \n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Get corresponding GeoJSON file\n",
    "        base_name = os.path.splitext(os.path.basename(image_path))[0]\n",
    "        geojson_path = os.path.join(data_path, f\"{base_name}.geojson\")\n",
    "        \n",
    "        if not os.path.exists(geojson_path):\n",
    "            continue\n",
    "        \n",
    "        # Load mask from GeoJSON\n",
    "        mask = load_geojson_mask(geojson_path, image.shape)\n",
    "        \n",
    "        # Resize image and mask\n",
    "        image_resized = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n",
    "        mask_resized = cv2.resize(mask, (IMG_SIZE, IMG_SIZE))\n",
    "        \n",
    "        # Normalize\n",
    "        image_normalized = image_resized.astype(np.float32) / 255.0\n",
    "        mask_normalized = (mask_resized > 127).astype(np.float32)\n",
    "        \n",
    "        images.append(image_normalized)\n",
    "        masks.append(mask_normalized)\n",
    "    \n",
    "    return np.array(images), np.array(masks)\n",
    "\n",
    "# Load the dataset\n",
    "print(\"Loading dataset...\")\n",
    "X, y = load_dataset(TRAIN_DATA_PATH)\n",
    "print(f\"Loaded {len(X)} images with shape {X.shape[1:]}\")\n",
    "print(f\"Masks shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951b602d",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036c5d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some examples\n",
    "fig, axes = plt.subplots(2, 6, figsize=(18, 6))\n",
    "\n",
    "for i in range(3):\n",
    "    # Original image\n",
    "    axes[0, i*2].imshow(X[i])\n",
    "    axes[0, i*2].set_title(f'Image {i+1}')\n",
    "    axes[0, i*2].axis('off')\n",
    "    \n",
    "    # Mask\n",
    "    axes[0, i*2+1].imshow(y[i], cmap='gray')\n",
    "    axes[0, i*2+1].set_title(f'Mask {i+1}')\n",
    "    axes[0, i*2+1].axis('off')\n",
    "    \n",
    "    # Overlay\n",
    "    overlay = X[i].copy()\n",
    "    overlay[:,:,0] = np.where(y[i] > 0.5, 1.0, overlay[:,:,0])\n",
    "    axes[1, i*2].imshow(overlay)\n",
    "    axes[1, i*2].set_title(f'Overlay {i+1}')\n",
    "    axes[1, i*2].axis('off')\n",
    "    \n",
    "    # Vessel statistics\n",
    "    vessel_ratio = np.mean(y[i])\n",
    "    axes[1, i*2+1].bar(['Vessel', 'Background'], [vessel_ratio, 1-vessel_ratio])\n",
    "    axes[1, i*2+1].set_title(f'Vessel Ratio: {vessel_ratio:.3f}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7850794c",
   "metadata": {},
   "source": [
    "## U-Net Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5b6b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(inputs, num_filters):\n",
    "    \"\"\"Convolutional block with batch normalization and dropout.\"\"\"\n",
    "    x = layers.Conv2D(num_filters, 3, padding=\"same\")(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "    \n",
    "    x = layers.Conv2D(num_filters, 3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def encoder_block(inputs, num_filters):\n",
    "    \"\"\"Encoder block with convolution and max pooling.\"\"\"\n",
    "    x = conv_block(inputs, num_filters)\n",
    "    p = layers.MaxPool2D((2, 2))(x)\n",
    "    return x, p\n",
    "\n",
    "def decoder_block(inputs, skip_features, num_filters):\n",
    "    \"\"\"Decoder block with upsampling and skip connections.\"\"\"\n",
    "    x = layers.Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(inputs)\n",
    "    x = layers.Concatenate()([x, skip_features])\n",
    "    x = conv_block(x, num_filters)\n",
    "    return x\n",
    "\n",
    "def build_unet(input_shape):\n",
    "    \"\"\"Build U-Net model.\"\"\"\n",
    "    inputs = layers.Input(input_shape)\n",
    "    \n",
    "    # Encoder\n",
    "    s1, p1 = encoder_block(inputs, 64)\n",
    "    s2, p2 = encoder_block(p1, 128)\n",
    "    s3, p3 = encoder_block(p2, 256)\n",
    "    s4, p4 = encoder_block(p3, 512)\n",
    "    \n",
    "    # Bridge\n",
    "    b1 = conv_block(p4, 1024)\n",
    "    \n",
    "    # Decoder\n",
    "    d1 = decoder_block(b1, s4, 512)\n",
    "    d2 = decoder_block(d1, s3, 256)\n",
    "    d3 = decoder_block(d2, s2, 128)\n",
    "    d4 = decoder_block(d3, s1, 64)\n",
    "    \n",
    "    # Output\n",
    "    outputs = layers.Conv2D(1, 1, padding=\"same\", activation=\"sigmoid\")(d4)\n",
    "    \n",
    "    model = keras.Model(inputs, outputs, name=\"U-Net\")\n",
    "    return model\n",
    "\n",
    "# Build the model\n",
    "model = build_unet((IMG_SIZE, IMG_SIZE, 3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229d99d5",
   "metadata": {},
   "source": [
    "## Loss Functions and Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62c5c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coefficient(y_true, y_pred, smooth=1e-6):\n",
    "    \"\"\"Dice coefficient for segmentation.\"\"\"\n",
    "    y_true_f = tf.keras.backend.flatten(y_true)\n",
    "    y_pred_f = tf.keras.backend.flatten(y_pred)\n",
    "    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) + smooth)\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    \"\"\"Dice loss function.\"\"\"\n",
    "    return 1 - dice_coefficient(y_true, y_pred)\n",
    "\n",
    "def combined_loss(y_true, y_pred):\n",
    "    \"\"\"Combined binary crossentropy and dice loss.\"\"\"\n",
    "    bce = tf.keras.losses.binary_crossentropy(y_true, y_pred)\n",
    "    dice = dice_loss(y_true, y_pred)\n",
    "    return bce + dice\n",
    "\n",
    "def iou_metric(y_true, y_pred, threshold=0.5):\n",
    "    \"\"\"Intersection over Union metric.\"\"\"\n",
    "    y_pred = tf.cast(y_pred > threshold, tf.float32)\n",
    "    intersection = tf.reduce_sum(y_true * y_pred)\n",
    "    union = tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) - intersection\n",
    "    return intersection / (union + 1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c182be72",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc28faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"Validation set: {X_val.shape[0]} samples\")\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "    loss=combined_loss,\n",
    "    metrics=[dice_coefficient, iou_metric, 'binary_accuracy']\n",
    ")\n",
    "\n",
    "# Callbacks\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        MODEL_SAVE_PATH,\n",
    "        monitor='val_dice_coefficient',\n",
    "        mode='max',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=5,\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    ),\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor='val_dice_coefficient',\n",
    "        mode='max',\n",
    "        patience=10,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fabc0c",
   "metadata": {},
   "source": [
    "## Training Results Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de790363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Loss\n",
    "axes[0, 0].plot(history.history['loss'], label='Training Loss')\n",
    "axes[0, 0].plot(history.history['val_loss'], label='Validation Loss')\n",
    "axes[0, 0].set_title('Model Loss')\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Loss')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# Dice Coefficient\n",
    "axes[0, 1].plot(history.history['dice_coefficient'], label='Training Dice')\n",
    "axes[0, 1].plot(history.history['val_dice_coefficient'], label='Validation Dice')\n",
    "axes[0, 1].set_title('Dice Coefficient')\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].set_ylabel('Dice Coefficient')\n",
    "axes[0, 1].legend()\n",
    "\n",
    "# IoU\n",
    "axes[1, 0].plot(history.history['iou_metric'], label='Training IoU')\n",
    "axes[1, 0].plot(history.history['val_iou_metric'], label='Validation IoU')\n",
    "axes[1, 0].set_title('IoU Metric')\n",
    "axes[1, 0].set_xlabel('Epoch')\n",
    "axes[1, 0].set_ylabel('IoU')\n",
    "axes[1, 0].legend()\n",
    "\n",
    "# Accuracy\n",
    "axes[1, 1].plot(history.history['binary_accuracy'], label='Training Accuracy')\n",
    "axes[1, 1].plot(history.history['val_binary_accuracy'], label='Validation Accuracy')\n",
    "axes[1, 1].set_title('Binary Accuracy')\n",
    "axes[1, 1].set_xlabel('Epoch')\n",
    "axes[1, 1].set_ylabel('Accuracy')\n",
    "axes[1, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print best scores\n",
    "best_val_dice = max(history.history['val_dice_coefficient'])\n",
    "best_val_iou = max(history.history['val_iou_metric'])\n",
    "print(f\"\\nBest Validation Dice Coefficient: {best_val_dice:.4f}\")\n",
    "print(f\"Best Validation IoU: {best_val_iou:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5449ec09",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3b6cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best model\n",
    "best_model = keras.models.load_model(\n",
    "    MODEL_SAVE_PATH,\n",
    "    custom_objects={\n",
    "        'combined_loss': combined_loss,\n",
    "        'dice_coefficient': dice_coefficient,\n",
    "        'iou_metric': iou_metric\n",
    "    }\n",
    ")\n",
    "\n",
    "# Evaluate on validation set\n",
    "val_results = best_model.evaluate(X_val, y_val, verbose=0)\n",
    "print(\"Validation Results:\")\n",
    "for name, value in zip(best_model.metrics_names, val_results):\n",
    "    print(f\"{name}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad34aea",
   "metadata": {},
   "source": [
    "## Prediction Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69548f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on validation set\n",
    "predictions = best_model.predict(X_val[:8])\n",
    "\n",
    "# Visualize predictions\n",
    "fig, axes = plt.subplots(4, 6, figsize=(18, 12))\n",
    "\n",
    "for i in range(4):\n",
    "    # Original image\n",
    "    axes[i, 0].imshow(X_val[i])\n",
    "    axes[i, 0].set_title('Original')\n",
    "    axes[i, 0].axis('off')\n",
    "    \n",
    "    # Ground truth\n",
    "    axes[i, 1].imshow(y_val[i], cmap='gray')\n",
    "    axes[i, 1].set_title('Ground Truth')\n",
    "    axes[i, 1].axis('off')\n",
    "    \n",
    "    # Prediction\n",
    "    pred = predictions[i, :, :, 0]\n",
    "    axes[i, 2].imshow(pred, cmap='gray')\n",
    "    axes[i, 2].set_title('Prediction')\n",
    "    axes[i, 2].axis('off')\n",
    "    \n",
    "    # Binary prediction\n",
    "    binary_pred = (pred > 0.5).astype(float)\n",
    "    axes[i, 3].imshow(binary_pred, cmap='gray')\n",
    "    axes[i, 3].set_title('Binary Pred')\n",
    "    axes[i, 3].axis('off')\n",
    "    \n",
    "    # Overlay\n",
    "    overlay = X_val[i].copy()\n",
    "    overlay[:,:,0] = np.where(binary_pred > 0.5, 1.0, overlay[:,:,0])\n",
    "    axes[i, 4].imshow(overlay)\n",
    "    axes[i, 4].set_title('Overlay')\n",
    "    axes[i, 4].axis('off')\n",
    "    \n",
    "    # Difference\n",
    "    diff = np.abs(y_val[i] - binary_pred)\n",
    "    axes[i, 5].imshow(diff, cmap='Reds')\n",
    "    axes[i, 5].set_title('Difference')\n",
    "    axes[i, 5].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a133cf06",
   "metadata": {},
   "source": [
    "## Model Export for Production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d78690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model info\n",
    "model_info = {\n",
    "    'model_type': 'U-Net',\n",
    "    'input_shape': [IMG_SIZE, IMG_SIZE, 3],\n",
    "    'output_shape': [IMG_SIZE, IMG_SIZE, 1],\n",
    "    'best_val_dice': float(best_val_dice),\n",
    "    'best_val_iou': float(best_val_iou),\n",
    "    'training_samples': len(X_train),\n",
    "    'validation_samples': len(X_val),\n",
    "    'epochs_trained': len(history.history['loss']),\n",
    "    'hyperparameters': {\n",
    "        'batch_size': BATCH_SIZE,\n",
    "        'learning_rate': LEARNING_RATE,\n",
    "        'image_size': IMG_SIZE\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save model info as JSON\n",
    "with open('../backend/models/model_info.json', 'w') as f:\n",
    "    json.dump(model_info, f, indent=2)\n",
    "\n",
    "print(\"Model training completed and saved successfully!\")\n",
    "print(f\"Model saved to: {MODEL_SAVE_PATH}\")\n",
    "print(f\"Final validation Dice coefficient: {best_val_dice:.4f}\")\n",
    "print(f\"Final validation IoU: {best_val_iou:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
